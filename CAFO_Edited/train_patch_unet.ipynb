{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch + SMp for deep learning\n",
        "\n",
        "rasterio for reading image patches\n",
        "\n",
        "numpy, random, pandas for arrays, randomness, and metrics\n",
        "\n",
        "torchvision.transforms.functional for augmentations\n",
        "\n",
        "sklearn.metrics for evaluation metrics"
      ],
      "metadata": {
        "id": "HpfBR7uPLz4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import segmentation_models_pytorch as smp\n",
        "import rasterio\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision.transforms.functional as TF\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n"
      ],
      "metadata": {
        "id": "mdWy_9xvL1RK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines directories for images, masks, model weights, and metrics.\n",
        "\n",
        "Creates output folders if missing.\n",
        "\n",
        "Sets batch size and number of epochs."
      ],
      "metadata": {
        "id": "Ujb7529KL2nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Base paths\n",
        "BASE_PATH = Path(\"/content/cafo_project\")\n",
        "IMG_DIR = BASE_PATH / \"patches/images\"\n",
        "MASK_DIR = BASE_PATH / \"patches/masks\"\n",
        "\n",
        "# Output paths\n",
        "MODEL_OUTPUT_PATH = BASE_PATH / \"weights/cafo_multi_patch.pt\"\n",
        "METRICS_OUTPUT_PATH = BASE_PATH / \"results/training_metrics.csv\"\n",
        "MODEL_OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "METRICS_OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 75\n"
      ],
      "metadata": {
        "id": "LQQoyzLeL42I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reads image and mask patches.\n",
        "\n",
        "Applies random flips and rotations for augmentation.\n",
        "\n",
        "Converts images/masks to PyTorch tensors."
      ],
      "metadata": {
        "id": "3j_sRI4kL9ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchDataset(Dataset):\n",
        "    def __init__(self, img_dir, mask_dir, augment=True):\n",
        "        self.img_dir = img_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.image_files = sorted(img_dir.glob(\"*.tif\"))\n",
        "        self.augment = augment\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        mask_path = self.mask_dir / img_path.name.replace(\".tif\", \"_mask.tif\")\n",
        "\n",
        "        with rasterio.open(img_path) as img_src:\n",
        "            img = img_src.read([1, 2, 3]) / 255.0\n",
        "        with rasterio.open(mask_path) as mask_src:\n",
        "            mask = mask_src.read(1)\n",
        "\n",
        "        img = torch.tensor(img, dtype=torch.float32)\n",
        "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # add channel\n",
        "\n",
        "        # Data augmentation\n",
        "        if self.augment:\n",
        "            if random.random() > 0.5:\n",
        "                img = TF.hflip(img)\n",
        "                mask = TF.hflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                img = TF.vflip(img)\n",
        "                mask = TF.vflip(mask)\n",
        "            if random.random() > 0.5:\n",
        "                k = random.choice([1, 2, 3])\n",
        "                img = torch.rot90(img, k, dims=[1, 2])\n",
        "                mask = torch.rot90(mask, k, dims=[1, 2])\n",
        "\n",
        "        return img, mask\n"
      ],
      "metadata": {
        "id": "xN9QeRhZMAMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wraps dataset in a DataLoader for batching and shuffling."
      ],
      "metadata": {
        "id": "mGT5AMG-MBSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = PatchDataset(IMG_DIR, MASK_DIR, augment=True)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
      ],
      "metadata": {
        "id": "vdD1iJCcMBG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "UNet with ResNet18 backbone pretrained on ImageNet.\n",
        "\n",
        "Binary segmentation â†’ use BCEWithLogitsLoss.\n",
        "\n",
        "Optimizer â†’ Adam."
      ],
      "metadata": {
        "id": "0cn4b7E7MFaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = smp.Unet(encoder_name=\"resnet18\", encoder_weights=\"imagenet\", in_channels=3, classes=1)\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()\n"
      ],
      "metadata": {
        "id": "v0zn9Wx6MHrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training with metric calculation per epoch.\n",
        "\n",
        "Stores metrics for later analysis."
      ],
      "metadata": {
        "id": "gR1MsAGEMJdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nðŸš€ Starting patch training loop with metrics tracking...\")\n",
        "model.train()\n",
        "metrics_log = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    all_preds, all_targets = [], []\n",
        "\n",
        "    for images, masks in dataloader:\n",
        "        images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        probs = torch.sigmoid(outputs)\n",
        "        preds = (probs > 0.5).float()\n",
        "        all_preds.append(preds.detach().cpu().numpy().ravel())\n",
        "        all_targets.append(masks.detach().cpu().numpy().ravel())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_targets = np.concatenate(all_targets)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc = accuracy_score(all_targets, all_preds)\n",
        "    prec = precision_score(all_targets, all_preds, zero_division=0)\n",
        "    rec = recall_score(all_targets, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_targets, all_preds, zero_division=0)\n",
        "    auc = roc_auc_score(all_targets, all_preds)\n",
        "    cm = confusion_matrix(all_targets, all_preds)\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    print(f\"\\nEpoch {epoch + 1}/{EPOCHS} | Loss: {avg_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | AUC: {auc:.4f}\")\n",
        "\n",
        "    metrics_log.append({\n",
        "        \"Epoch\": epoch + 1,\n",
        "        \"Loss\": avg_loss,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1\": f1,\n",
        "        \"AUC-ROC\": auc,\n",
        "        \"TP\": cm[1, 1] if cm.shape == (2,2) else 0,\n",
        "        \"FP\": cm[0, 1] if cm.shape == (2,2) else 0,\n",
        "        \"FN\": cm[1, 0] if cm.shape == (2,2) else 0,\n",
        "        \"TN\": cm[0, 0] if cm.shape == (2,2) else 0,\n",
        "    })\n"
      ],
      "metadata": {
        "id": "5eib_hwfMMMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saves trained model weights.\n",
        "\n",
        "Saves metrics CSV for plotting or further analysis."
      ],
      "metadata": {
        "id": "1vDHxv7vMOMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), MODEL_OUTPUT_PATH)\n",
        "print(f\"\\nâœ… Training complete. Model saved to {MODEL_OUTPUT_PATH}\")\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_log)\n",
        "metrics_df.to_csv(METRICS_OUTPUT_PATH, index=False)\n",
        "print(f\"ðŸ“„ Training metrics saved to {METRICS_OUTPUT_PATH}\")\n"
      ],
      "metadata": {
        "id": "VyTc_jHVMQkc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}